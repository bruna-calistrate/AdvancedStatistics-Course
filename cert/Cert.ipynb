{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Carregar biblioteca e funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibiotecas padrão\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Visualização de dados\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "# Escrever as fórmulas dos modelos\n",
    "import patsy as pt\n",
    "\n",
    "# Bibioteca estatística\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Fator de inflação da variância\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Bibliotecas do scikitlearn para calcular as métricas e fazer a regressão regularizada\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedKFold, cross_val_score\n",
    "from sklearn.linear_model import Ridge, RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desc_null(df, percentiles=False):\n",
    "  \"\"\"Função para descrição de dados, incluindo colunas de contagem de nulos e porcentagem de nulos em cada variável\n",
    "\n",
    "  Args:\n",
    "      df (pd.DataFrame): base de dados para descrição\n",
    "      percentiles (bool, optional): exibição dos percentis [0.05, 0.25, 0.5, 0.75, 0.9, 0.99]. Defaults to False.\n",
    "\n",
    "  Returns:\n",
    "      des(pd.DataFrame): descrição dos dados com a quantidade e porcentagem de nulos por feature\n",
    "  \"\"\"  \n",
    "  import pandas as pd\n",
    "\n",
    "  if percentiles is True:\n",
    "    des = df.describe(datetime_is_numeric=True,\n",
    "                      percentiles=[0.05, 0.25, 0.5, 0.75, 0.9, 0.99]).T\n",
    "    des[\"nullCount\"] = df.shape[0] - des[\"count\"]\n",
    "    des[\"null%\"] = (des[\"nullCount\"] / df.shape[0]) * 100\n",
    "\n",
    "  else:\n",
    "    des = df.describe(include='all', \n",
    "                      datetime_is_numeric=True).T\n",
    "    des['nullCount'] = df.shape[0] - des['count']\n",
    "    des['null%'] = (des['nullCount'] / df.shape[0]) * 100\n",
    "    \n",
    "  return des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_filter(df, columns, entries, drop_first=True):\n",
    "  \"\"\"Filtro de categorias, gera uma nova categoria Others com os menos representativos, retornando nova base com os dados dummyficados\n",
    "\n",
    "  Args:\n",
    "      df (pd.DataFrame): base de dados\n",
    "      columns (list): lista com as colunas com dados categóricos\n",
    "      entries (int): quantidade mínima de entradas significativas de categorias\n",
    "      drop_first(bool, optional): remoção da primeira categoria para evitar multicolinearidade. Defaults to True.\n",
    "\n",
    "  Returns:\n",
    "      df(pd.DataFrame): base de dados com a dummyficação dos valores categóricos\n",
    "  \"\"\"  \n",
    "  import pandas as pd\n",
    "  \n",
    "  filter = {}\n",
    "  for col in columns:\n",
    "    cat = df[col].value_counts().sort_values(ascending=True)\n",
    "    filter = {x: 'Other' for x in cat[cat < entries].index}\n",
    "    \n",
    "  df.loc[:, col] = df[col].replace(filter).copy()\n",
    "  df = pd.get_dummies(df, columns=columns, drop_first=drop_first)\n",
    "  \n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histplot(data, title=None, xlabel=None, ylabel=None, x=None, y=None, ax=False, nrows=1, ncols=1, figsize=(10, 5), bins=10):\n",
    "  \"\"\"Gráfico de frequência pra visualização de dados numéricos e categóricos\n",
    "\n",
    "  Args:\n",
    "      data (pd.DataFrame): base de dados\n",
    "      title (str, optional): título do gráfico, opcional. Defaults to None.\n",
    "      xlabel (str, optional): título do eixo x, opcional. Defaults to None.\n",
    "      ylabel (str, optional): título do eixo y, opcional. Defaults to None.\n",
    "      x (str, optional): feature da base de dados para o eixo x. Defaults to None.\n",
    "      y (str, optional): feature da base de dados para o eixo y. Defaults to None.\n",
    "      ax (bool, optional): determina se a impressão conterá múltiplos gráficos. Defaults to False.\n",
    "      nrows (int, optional): quantidade de linhas. Defaults to 1.\n",
    "      ncols (int, optional): quantidade de colunas. Defaults to 1.\n",
    "      figsize (tuple, optional): tamanho da impressão. Defaults to (10, 5).\n",
    "      bins (int, optional): quantidade de bins. Defaults to 10.\n",
    "\n",
    "  Returns:\n",
    "      sns.histplot: impressão do gráfico\n",
    "  \"\"\"  \n",
    "  import matplotlib.pyplot as plt\n",
    "  import seaborn as sns\n",
    "  \n",
    "  if ax is True:\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
    "    c = 0\n",
    "    if len(x) < (nrows * ncols):      \n",
    "      for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "          if i == nrows-1 and j == ncols-1:\n",
    "            fig.delaxes(axes[nrows-1,ncols-1])\n",
    "          else:\n",
    "            sns.histplot(data=data, x=x[c], y=y, bins=bins, ax=axes[i,j]).set_ylabel(ylabel)\n",
    "            c += 1\n",
    "      \n",
    "    elif nrows > 1 and ncols > 1:      \n",
    "      for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "          sns.histplot(data=data, x=x[c], y=y, bins=bins, ax=axes[i,j]).set_ylabel(ylabel)\n",
    "          c += 1\n",
    "    elif nrows == 1:\n",
    "      for j in range(ncols):\n",
    "        sns.histplot(data=data, x=x[c], y=y, bins=bins, ax=axes[j]).set_ylabel(ylabel)\n",
    "        c += 1\n",
    "    elif ncols == 1:\n",
    "      for i in range(nrows):\n",
    "        sns.histplot(data=data, x=x[c], y=y, bins=bins, ax=axes[i]).set_ylabel(ylabel)\n",
    "        c += 1\n",
    "    if title is not None:\n",
    "      fig.suptitle(title)\n",
    "  \n",
    "  else:\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.histplot(data=data, x=x, y=y, bins=bins)\n",
    "    \n",
    "    if title is not None:\n",
    "      plt.title(title)\n",
    "    if xlabel is not None:\n",
    "      plt.xlabel(xlabel)\n",
    "    if ylabel is not None:\n",
    "      plt.ylabel(ylabel)\n",
    "      \n",
    "  return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrplot(data):\n",
    "    \"\"\"Gráfico de correlação com paleta de cores do azul ao vermelho e anotações para melhor entendimento dos dados\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): base de dados para realizar a correlação\n",
    "\n",
    "    Returns:\n",
    "        sns.heatmap: impressão do gráfico\n",
    "    \"\"\"    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "\n",
    "    sns.heatmap(\n",
    "        data=data.corr(),\n",
    "        cmap=sns.diverging_palette(230, 20, as_cmap=True),\n",
    "        vmin=-1,\n",
    "        vmax=1,\n",
    "        annot=True,\n",
    "    )\n",
    "\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_test(df):\n",
    "    \"\"\"Realiza teste de normalidade de Kolmorogov no resíduo da previsão\n",
    "\n",
    "    Args:\n",
    "        df (pd.Series): resíduo da previsão\n",
    "\n",
    "    Returns:\n",
    "        data(pd.DataFrame): tabela com as informações estatísticas e P-Value do resíduo de previsão\n",
    "    \"\"\" \n",
    "    import scipy as sp\n",
    "    import pandas as pd\n",
    "\n",
    "    kStat, kPvalue = sp.stats.kstest(df, 'norm')\n",
    "    data = pd.DataFrame({'kStat': kStat,\n",
    "                         'P-Value': kPvalue},\n",
    "                        index=['Kolmogrov']).round(decimals=5)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_scale(x):\n",
    "    \"\"\"Escalonar as variáveis numéricas da base de dados\n",
    "\n",
    "    Args:\n",
    "        x (pd.DataFrame): base de dados com as variáveis numéricas\n",
    "\n",
    "    Returns:\n",
    "        xnorm(float): valores escalonados\n",
    "    \"\"\"    \n",
    "    import numpy as np\n",
    "\n",
    "    # Calcular a média da variável\n",
    "    mean = np.mean(x, axis=0)\n",
    "\n",
    "    # Calcular o desvio padrão amostral da variável\n",
    "    sigma = np.std(x, axis=0, ddof=1)\n",
    "\n",
    "    # Realizar o escalonamento\n",
    "    xnorm = (x - mean) / sigma\n",
    "\n",
    "    return xnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols_formula(df, dependent_var, *excluded_rows):\n",
    "    \"\"\"Fórmula para seleção das colunas para gerar a matriz dos dados\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): base de dados\n",
    "        dependent_var (str): variável resposta\n",
    "        * excluded_rows (str): variáveis a serem excluídas\n",
    "\n",
    "    Returns:\n",
    "        dependent_var(list): relação das colunas para criação da matriz\n",
    "    \"\"\"    \n",
    "\n",
    "    # Listar o nome das colunas do dataframe\n",
    "    cols = list(df.columns)\n",
    "\n",
    "    # Remover a variável dependente\n",
    "    cols.remove(dependent_var)\n",
    "\n",
    "    # Remover as variáveis excluídas\n",
    "    for col in excluded_rows:\n",
    "        cols.remove(col)\n",
    "\n",
    "    # Retornar a fórmula\n",
    "    return dependent_var + \" ~ \" + \" + \".join(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(y, x, type='OLS', alpha=1.0):\n",
    "  \n",
    "  \"\"\"Ajuste do modelo para os métodos OLS e Ridge\n",
    "\n",
    "  Args:\n",
    "      y (pd.DataFrame): variável resposta\n",
    "      x (pd.DataFrame): regressores\n",
    "      type (str, optional): tipo de modelo OLS ou Ridge. Defaults to 'OLS'.\n",
    "      alpha (float, optional): alpha do modelo Ridge para ajuste. Defaults to 1.0.\n",
    "\n",
    "  Returns:\n",
    "      regfit(): modelo ajustado\n",
    "  \"\"\"  \n",
    "  import statsmodels.api as sm\n",
    "  from sklearn.linear_model import Ridge\n",
    "  \n",
    "  if type == 'OLS':\n",
    "    reg = sm.OLS(y, x)\n",
    "    regfit = reg.fit()\n",
    "  elif type == 'Ridge':\n",
    "    regfit = Ridge(alpha=alpha)\n",
    "    regfit.fit(x, y)\n",
    "\n",
    "  return regfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vif_view(x, intercept=False):\n",
    "    \"\"\"Fator de inflação da variância\n",
    "\n",
    "    Args:\n",
    "            x (pd.DataFrame): base de dados dos regressores\n",
    "            intercept (bool, optional): considerar ou não a coluna Intercept. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "            vif(pd.DataFrame): tabela com as variáveis e seus respectivos VIFs\n",
    "    \"\"\"    \n",
    "    import pandas as pd\n",
    "    from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "    if intercept is True:\n",
    "            vif = pd.DataFrame({'Variáveis': x.columns[1:],\n",
    "                                'VIF': [variance_inflation_factor(x.values, i + 1)\n",
    "                                        for i in range(len(x.columns[1:]))]\n",
    "                            })\n",
    "    else:\n",
    "            vif = pd.DataFrame({'Variáveis': x.columns,\n",
    "                                'VIF': [variance_inflation_factor(x.values, i + 1)\n",
    "                                        for i in range(len(x.columns))]\n",
    "                            })\n",
    "            \n",
    "    return vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_table(y, fit, columns, residual=False):\n",
    "    \"\"\"Tabela de previsão e cálculo de resíduo do modelo\n",
    "\n",
    "    Args:\n",
    "        y (pd.DataFrame): variável resposta\n",
    "        fit (.predict): predição do modelo ajustado dos regressores\n",
    "        columns (list): nome das colunas Real e Previsto\n",
    "        residual (bool, optional): cálculo do residual dos regressores. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        pred(pd.DataFrame): base com predição do modelo ajustado\n",
    "    \"\"\"    \n",
    "    import pandas as pd\n",
    "    \n",
    "    pred = pd.concat([y, fit], axis=1)\n",
    "    pred.columns = columns\n",
    "\n",
    "    if residual is True:\n",
    "        pred['Res'] = pred[columns[0]] - pred[columns[1]]\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_quality(pred):\n",
    "    \"\"\"Qualidade de ajuste do modelo com R² e RMSE\n",
    "\n",
    "    Args:\n",
    "        pred (pd.DataFrame): tabela de previsão do modelo\n",
    "\n",
    "    Returns:\n",
    "        adj(pd.DataFrame): cálculo de R² e RMSE do modelo\n",
    "    \"\"\"    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn import metrics\n",
    "\n",
    "    adj = pd.DataFrame({\n",
    "        'R²': metrics.r2_score(pred.loc[:, pred.columns[0]], \n",
    "                               pred.loc[:, pred.columns[1]]),\n",
    "        'RMSE': np.sqrt(metrics.mean_squared_error(pred.loc[:, pred.columns[0]], \n",
    "                                                   pred.loc[:, pred.columns[1]]))\n",
    "    }, index=[0])\n",
    "\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_perda(x, y, beta):\n",
    "    \"\"\"Cria a função de perda para o gradiente descendente\n",
    "\n",
    "    Args:\n",
    "        x (pd.DataFrame): matriz dos regressores\n",
    "        y (pd.Series): série com a resposta\n",
    "        beta (np.array): série dos parâmetros\n",
    "\n",
    "    Returns:\n",
    "        perda: cálculo da perda\n",
    "    \"\"\"    \n",
    "    import numpy as np\n",
    "\n",
    "    m, n = x.shape\n",
    "\n",
    "    # Previsão da resposta: produto escalar entre os vetores de parâmetros e o dataframe com os regressores - produto escalar entre x e beta\n",
    "    pred = x.dot(beta)\n",
    "\n",
    "    # Calcular os erros de previsão: é a diferença entre o valor real da variável y e o valor previsto pelo modelo - resíduo\n",
    "    res = np.subtract(pred, y.squeeze())\n",
    "\n",
    "    # Calcular o quadrado dos erros\n",
    "    sqrRes = np.square(res)\n",
    "\n",
    "    # Calcular a perda\n",
    "    perda = 1 / (2 * m) * np.sum(sqrRes)\n",
    "\n",
    "    return perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_des(x, y, alpha, itera):\n",
    "    \"\"\"Cálculo do gradiente descendente\n",
    "\n",
    "    Args:\n",
    "        x (pd.DataFrame): matriz dos regressores\n",
    "        y (pd.Series): série da resposta\n",
    "        alpha (float): taxa de aprendizagem escalar do modelo\n",
    "        itera (int): número de iterações do algoritmo\n",
    "\n",
    "    Returns:\n",
    "        beta(pd.Series): série com os valores finais dos parâmetros\n",
    "        hPerda(pd.Series): série com o histórico de perdas\n",
    "    \"\"\"    \n",
    "    import numpy as np\n",
    "\n",
    "    # Define o número de linhas e o de regressores\n",
    "    m, n = x.shape\n",
    "    \n",
    "    # Inicializa os valores dos betas\n",
    "    beta = np.zeros(n)\n",
    "\n",
    "    # Inicializa a série do histórico de perdas: ajuda a encontrar os melhores valores de alpha para alcançar uma melhor convergência\n",
    "    hPerda = np.zeros(itera)\n",
    "\n",
    "    for i in range(itera):\n",
    "\n",
    "        # Calcula as previsões com os valores atuais dos parâmetros\n",
    "        pred = x.dot(beta)\n",
    "\n",
    "        # Calcula os resíduos de previsão: previsão - resposta\n",
    "        res = np.subtract(pred, y.squeeze())\n",
    "\n",
    "        # Calcula o incremento/decremento valor dos betas - derivada parcial da função perda:\n",
    "        # quanto maior o alpha, maior o passo que o algoritmo dará para o próximo beta\n",
    "        sumDelta = (alpha / m) * x.transpose().dot(res)\n",
    "\n",
    "        # Atualizar os valores dos betas do modelo\n",
    "        beta = beta - sumDelta\n",
    "\n",
    "        # Calcula a nova perda com os novos valores dos betas\n",
    "        hPerda[i] = funcao_perda(x, y, beta)\n",
    "\n",
    "    return beta, hPerda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Carregar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Análise Exproratória dos dados\n",
    "\n",
    "## 3.1. Separação das variáveis e tratamento de nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_null(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. Variáveis categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = []\n",
    "\n",
    "dfCat = df.loc[:, c]\n",
    "dfCat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. Variáveis numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = []\n",
    "resp = []\n",
    "# num = list(df.select_dtypes(include=''))\n",
    "# num.remove(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNum = df.loc[:, num]\n",
    "dfNum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_null(dfNum, percentiles=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3. Variável resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResp = df.loc[:, resp]\n",
    "dfResp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Distribuição das variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histplot(data=dfCat, \n",
    "         title='Distribuição das variáveis categóricas', \n",
    "         ylabel='Frequência',\n",
    "         x=cat, ax=True,\n",
    "         ncols=2, nrows=,\n",
    "         bins=15,\n",
    "         figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histplot(data=dfNum, \n",
    "         title='Distribuição das variáveis numéricas', \n",
    "         ylabel='Frequência',\n",
    "         x=num, ax=True,\n",
    "         ncols=2, nrows=,\n",
    "         bins=15,\n",
    "         figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
